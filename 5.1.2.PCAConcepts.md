## Purpose
PCA is a powerfull technique to reduce the demensionality of large datasets
- increase interpretability
- while retaining information(relatively reducing information loss)
- used in exploratory data analysis, making predictive models more efficient by reducing the number of features, and in visualizations to make large number of features feasible to plot

Look at scatter plot one X and one Y at a time is way too time consuming and does not really tell the inter-relationship(correlations) between the variables. 

## How is this acheieve?
Principle Component Analysis essentially transforms data into non-correlated variables. The first principle component accounts for the largest possible variance in the data set. 

### Math behind PCA
Given a set of feature:
$$X_1, X_2, ..., X_p$$
We want to find a linear combination of these features that will maximize the variance of the data, and we call this normalized variance $Z_1$ and call this linear combination the first principle component.
$$Z_1 = \Phi_{11}X_1 + \Phi_{21}X_2 + ... + \Phi_{p1}X_p$$
where $\Phi$ satisfies the following:
$$\Phi^{2}_{11} + ... + \Phi^{2}_{p1} = 1$$

The second principle component is the linear combination of the features that maximizes the variance of the data, subject to the constraint that it is uncorrelated with the first principle component.

This process can continue until we have as many principle components as we have features, but they are not as meaningful to look at as the first few principle components.

When you see a vectort plot:
- positively correlated features will point to the same direction
- negatively correlated features will point to the opposite direction
- can also derive the percentage of variance explained by each principle component knowing the total variance of the dataset. 

> Essentially, PCA aims to capture as much of the variance in the original dataset as possible using a reduced number of uncorrelated features (principal components). These principal components are linear combinations of the original features, ordered by the amount of variance they explain.